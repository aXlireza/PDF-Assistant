{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import textwrap\n",
    "import warnings\n",
    "import pyperclip\n",
    "import soundfile as sf\n",
    "from pynput import keyboard\n",
    "from plyer import notification\n",
    "from playsound import playsound\n",
    "from num2words import num2words\n",
    "from transformers import BigBirdPegasusForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "# this is \n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "os.system(\"export CUDA_VISIBLE_DEVICES=\\\"\\\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SUMMERIZATION models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # facebook/bart-large-cnn\n",
    "# from transformers import pipeline\n",
    "# summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "# def facebook_bart_large_cnn(text):\n",
    "#     summary = summarizer(text, max_length=20 if len(text.split())<=50 else 70, min_length=10, do_sample=False)\n",
    "#     return summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google/bigbird-pegasus-large-bigpatent\n",
    "summarytokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-bigpatent\")\n",
    "summarymodel = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-bigpatent\", attention_type=\"original_full\")\n",
    "def google_bigbird_pegasus_large_bigpatent(text):\n",
    "    inputs = summarytokenizer(text, return_tensors='pt')\n",
    "    summaryprediction = summarymodel.generate(**inputs)\n",
    "    thesummary = summarytokenizer.batch_decode(summaryprediction)\n",
    "    return thesummary[0].replace('<s>', '').replace('</s>', '').strip()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Text To Speech models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # microsoft/speecht5_tts\n",
    "# import torch\n",
    "# from datasets import load_dataset\n",
    "# from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech, SpeechT5HifiGan\n",
    "# processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "# model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "# vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")\n",
    "# embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "# speaker_embeddings = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "\n",
    "# def microsoft_speecht5_tts(text):\n",
    "#     inputs = processor(text=text, return_tensors=\"pt\")\n",
    "#     return model.generate_speech(inputs[\"input_ids\"], speaker_embeddings, vocoder=vocoder), 22000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:07:01.788135: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-12 17:07:01.788168: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-12 17:07:01.789143: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-12 17:07:03.226350: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-02-12 17:07:04 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482a9bcb58fd4473ae30dde714aabdaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 17:07:05 | INFO | fairseq.tasks.speech_to_text | dictionary size (vocab.txt): 75\n",
      "/home/alireza/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "2024-02-12 17:07:07 | INFO | fairseq.models.text_to_speech.vocoder | loaded HiFiGAN checkpoint from /home/alireza/.cache/fairseq/models--facebook--fastspeech2-en-ljspeech/snapshots/a3e3e5e2e62bb7ca7514b11aa469e9c5b01a20bf/hifigan.bin\n"
     ]
    }
   ],
   "source": [
    "# facebook/fastspeech2-en-ljspeech\n",
    "from fairseq.checkpoint_utils import load_model_ensemble_and_task_from_hf_hub\n",
    "from fairseq.models.text_to_speech.hub_interface import TTSHubInterface\n",
    "fairseqmodels, fairseqcfg, fairseqtask = load_model_ensemble_and_task_from_hf_hub(\n",
    "    \"facebook/fastspeech2-en-ljspeech\",\n",
    "    arg_overrides={\"vocoder\": \"hifigan\", \"fp16\": False}\n",
    ")\n",
    "fairseqmodel = fairseqmodels[0].to('cpu')\n",
    "TTSHubInterface.update_cfg_with_data_cfg(fairseqcfg, fairseqtask.data_cfg)\n",
    "generator = fairseqtask.build_generator(fairseqmodels, fairseqcfg)\n",
    "\n",
    "def facebook_fastspeech2_en_ljspeech(text):\n",
    "    sample = TTSHubInterface.get_model_input(fairseqtask, text)\n",
    "    return TTSHubInterface.get_prediction(fairseqtask, fairseqmodel, generator, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_notification(title, message):\n",
    "    notification.notify(\n",
    "        title=title,\n",
    "        message=message,\n",
    "        timeout=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summerize(text):\n",
    "    print(len(text.split()))\n",
    "    print(textwrap.fill(text, 80))\n",
    "\n",
    "    # return facebook_bart_large_cnn(text)\n",
    "    return google_bigbird_pegasus_large_bigpatent(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readoutload(text):\n",
    "    # wav, rate = microsoft_speecht5_tts(text)\n",
    "    wav, rate = facebook_fastspeech2_en_ljspeech(text)\n",
    "    \n",
    "    sf.write(\"nowgeneratedspeechforstudy.wav\", wav, samplerate=rate)\n",
    "    show_notification(\"summary\", text)\n",
    "    playsound(\"nowgeneratedspeechforstudy.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers_to_text(text):\n",
    "    # Regular expression pattern to match numbers\n",
    "    pattern = r'\\b\\d+\\b'\n",
    "    \n",
    "    def replace(match):\n",
    "        number = int(match.group())\n",
    "        return num2words(number)\n",
    "    \n",
    "    # Replace numbers in the text with their textual representation\n",
    "    converted_text = re.sub(pattern, replace, text)\n",
    "\n",
    "    return converted_text\n",
    "\n",
    "def preprocesstext(text):\n",
    "    text = text.strip()\n",
    "    text = text.replace('-\\n', '')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    text = convert_numbers_to_text(text)\n",
    "    # text = text.replace(\".\", \",\").replace(\"!\", \",\").replace(\"?\", \",\").replace(\":\", \",\").replace(\";\", \",\")\n",
    "    text = text.replace(\"(\",',').replace(\")\",',').replace(\"[\",',').replace(\"]\",',').replace(\"{\",',').replace(\"}\",',')\n",
    "    text = text.replace('\"',',').replace(\"“\",',').replace(\"”\",',')\n",
    "    text = text.replace(\"-\",' ').replace(\"_\",' ').replace(\"—\",' ').replace(\"–\",' ').replace(\"…\",' ')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_originaltext = ''\n",
    "def generatebytext(originaltext, mode):\n",
    "    global prev_originaltext\n",
    "    originaltext = preprocesstext(originaltext)\n",
    "\n",
    "    if mode == 'stts':\n",
    "        if originaltext != prev_originaltext:\n",
    "            \n",
    "            thesummary = originaltext if len(originaltext.split())<=10 else summerize(originaltext)\n",
    "            thesummarysplitted = [substr for substr in re.split(r\"[.!?;:]\", thesummary) if substr]\n",
    "            print(thesummarysplitted)\n",
    "            for tmptext in thesummarysplitted: readoutload(tmptext)\n",
    "            prev_originaltext = thesummary\n",
    "    elif mode == 'tts':\n",
    "        if originaltext != prev_originaltext:\n",
    "            thesummarysplitted = [substr for substr in re.split(r\"[.!?;:]\", originaltext) if substr]\n",
    "            print(thesummarysplitted)\n",
    "            for tmptext in thesummarysplitted: readoutload(tmptext)\n",
    "            prev_originaltext = originaltext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anti cancer drugs', ' Potent cytokines and monoclonal antibodies']\n"
     ]
    }
   ],
   "source": [
    "generatebytext(\"anti-cancer drugs. Potent cytokines and monoclonal antibodies\", \"tts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generatebytext(\"a\", \"stts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('./output.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['directed against cell surface associated structures are already promi ']\n"
     ]
    }
   ],
   "source": [
    "generatebytext(data['Page'][0]['TextLine'][2][\"text\"], \"tts\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
